apiVersion: pac.weave.works/v1
kind: Policy
metadata:
  name: weave.policies.containers-running-with-privilege-escalation
spec:
  id: weave.policies.containers-running-with-privilege-escalation
  name: Containers Running With Privilege Escalation
  description: |
    Containers are running with PrivilegeEscalation configured. Setting this Policy to `true` allows child processes to gain more privileges than its parent process.

    This Policy gates whether or not a user is allowed to set the security context of a container to `allowPrivilegeEscalation` to `true`. The default value for this is `false` so no child process of a container can gain more privileges than its parent.

    There are 2 parameters for this Policy:
    - exclude_namespace (string) : This sets a namespace you want to exclude from Policy compliance checking.
    - allow_privilege_escalation (bool) : This checks for the value of `allowPrivilegeEscalation` in your spec.
  how_to_solve: |
    Check the following path to see what the PrivilegeEscalation value is set to.
    ```
    ...
      spec:
        containers:
          securityContext:
            allowPrivilegeEscalation: <value>
    ```
    https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  category: weave.categories.pod-security
  severity: high
  targets: {kinds: [Deployment, Job, ReplicationController, ReplicaSet, DaemonSet, StatefulSet, CronJob]}
  controls:
    - weave.controls.pci-dss.2.2.4
    - weave.controls.pci-dss.2.2.5
    - weave.controls.cis-benchmark.5.2.5
    - weave.controls.mitre-attack.4.1
    - weave.controls.nist-800-190.3.3.2
    - weave.controls.gdpr.25
    - weave.controls.gdpr.32
    - weave.controls.gdpr.24
    - weave.controls.soc2-type-i.1.6.1
  tags: [pci-dss, cis-benchmark, mitre-attack, nist800-190, gdpr, default, soc2-type1]
  parameters:
    - name: exclude_namespace
      type: array
      required: true
      value: ["kube-system", "wego-system", "flux-system"]
    - name: allow_privilege_escalation
      type: boolean
      required: true
      value: false
    - name: exclude_label_key
      type: string
      required: false
      value:
    - name: exclude_label_value
      type: string
      required: false
      value:
  code: |-
    package weave.advisor.podSecurity.privilegeEscalation
    import future.keywords.in

    excluded_namespaces := input.parameters.exclude_namespace
    allow_privilege_escalation := input.parameters.allow_privilege_escalation
    exclude_label_key := input.parameters.exclude_label_key
    exclude_label_value := input.parameters.exclude_label_value

    violation[result] {
      not controller_input.metadata.namespace in excluded_namespaces
      not exclude_label_value == controller_input.metadata.labels[exclude_label_key]
      containers := controller_spec.containers[i]
      allow_priv := containers.securityContext.allowPrivilegeEscalation
      not allow_priv == allow_privilege_escalation
      result = {
        "issue detected": true,
        "msg": sprintf("Container's privilegeEscalation should be set to '%v'; detected '%v'", [allow_privilege_escalation, allow_priv]),
        "violating_key": sprintf("spec.template.spec.containers[%v].securityContext.allowPrivilegeEscalation", [i]),
        "recommended_value": allow_privilege_escalation
      }
    }

    is_array_contains(array,str) {
      array[_] = str
    }

    # Controller input
    controller_input = input.review.object

    # controller_container acts as an iterator to get containers from the template
    controller_spec = controller_input.spec.template.spec {
      contains_kind(controller_input.kind, {"StatefulSet" , "DaemonSet", "Deployment", "Job"})
    } else = controller_input.spec {
      controller_input.kind == "Pod"
    } else = controller_input.spec.jobTemplate.spec.template.spec {
      controller_input.kind == "CronJob"
    }

    contains_kind(kind, kinds) {
      kinds[_] = kind
    }
---
apiVersion: pac.weave.works/v1
kind: Policy
metadata:
  name: weave.policies.container-running-as-root
spec:
  id: weave.policies.container-running-as-root
  name: Container Running As Root
  description: |
    Running as root gives the container full access to all resources in the VM it is running on. Containers should not run with such access rights unless required by design. This Policy enforces that the `securityContext.runAsNonRoot` attribute is set to `true`.
  how_to_solve: |
    You should set `securityContext.runAsNonRoot` to `true`. Not setting it will default to giving the container root user rights on the VM that it is running on.
    ```
    ...
      spec:
        securityContext:
          runAsNonRoot: true
    ```
    https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  category: weave.categories.pod-security
  severity: high
  targets: {kinds: [Deployment, Job, ReplicationController, ReplicaSet, DaemonSet, StatefulSet, CronJob]}
  controls:
    - weave.controls.pci-dss.2.2.4
    - weave.controls.pci-dss.2.2.5
    - weave.controls.cis-benchmark.5.2.6
    - weave.controls.mitre-attack.4.1
    - weave.controls.nist-800-190.3.3.1
    - weave.controls.gdpr.24
    - weave.controls.gdpr.25
    - weave.controls.gdpr.32
  tags: [pci-dss, cis-benchmark, mitre-attack, nist800-190, gdpr, default]
  parameters:
    - name: exclude_namespace
      type: array
      required: false
      value: ["kube-system", "wego-system", "flux-system"]
    - name: exclude_label_key
      type: string
      required: false
      value:
    - name: exclude_label_value
      type: string
      required: false
      value:
  code: |-
    package weave.advisor.podSecurity.runningAsRoot
    import future.keywords.in

    excluded_namespaces := input.parameters.exclude_namespace
    exclude_label_key := input.parameters.exclude_label_key
    exclude_label_value := input.parameters.exclude_label_value

    # Check for missing securityContext.runAsNonRoot (missing in both, pod and container)
    violation[result] {
    	not controller_input.metadata.namespace in excluded_namespaces
    	not exclude_label_value == controller_input.metadata.labels[exclude_label_key]

    	controller_spec.securityContext
    	not controller_spec.securityContext.runAsNonRoot
    	not controller_spec.securityContext.runAsNonRoot == false

    	some i
    	containers := controller_spec.containers[i]
    	containers.securityContext
    	not containers.securityContext.runAsNonRoot
    	not containers.securityContext.runAsNonRoot == false

    	result = {
    		"issue detected": true,
    		"msg": sprintf("Container missing spec.template.spec.containers[%v].securityContext.runAsNonRoot while Pod spec.template.spec.securityContext.runAsNonRoot is not defined as well.", [i]),
    		"violating_key": sprintf("spec.template.spec.containers[%v].securityContext", [i]),
    	}
    }

    # Container security context
    # Check if containers.securityContext.runAsNonRoot exists and = false
    violation[result] {
    	not controller_input.metadata.namespace in excluded_namespaces
    	not exclude_label_value == controller_input.metadata.labels[exclude_label_key]

    	some i
    	containers := controller_spec.containers[i]
    	containers.securityContext
    	containers.securityContext.runAsNonRoot == false

    	result = {
    		"issue detected": true,
    		"msg": sprintf("Container spec.template.spec.containers[%v].securityContext.runAsNonRoot should be set to true ", [i]),
    		"violating_key": sprintf("spec.template.spec.containers[%v].securityContext.runAsNonRoot", [i]),
    		"recommended_value": true,
    	}
    }

    # Pod security context
    # Check if spec.securityContext.runAsNonRoot exists and = false
    violation[result] {
    	not controller_input.metadata.namespace in excluded_namespaces
    	not exclude_label_value == controller_input.metadata.labels[exclude_label_key]

    	controller_spec.securityContext
    	controller_spec.securityContext.runAsNonRoot == false

    	result = {
    		"issue detected": true,
    		"msg": "Pod spec.template.spec.securityContext.runAsNonRoot should be set to true",
    		"violating_key": "spec.template.spec.securityContext.runAsNonRoot",
    		"recommended_value": true,
    	}
    }

    controller_input = input.review.object

    controller_spec = controller_input.spec.template.spec {
    	contains(controller_input.kind, {"StatefulSet", "DaemonSet", "Deployment", "Job", "ReplicaSet"})
    } else = controller_input.spec {
    	controller_input.kind == "Pod"
    } else = controller_input.spec.jobTemplate.spec.template.spec {
    	controller_input.kind == "CronJob"
    }

    contains(kind, kinds) {
    	kinds[_] = kind
    }
---
apiVersion: pac.weave.works/v1
kind: Policy
metadata:
  name: weave.policies.containers-read-only-root-filesystem
spec:
  id: weave.policies.containers-read-only-root-filesystem
  name: Containers Read Only Root Filesystem
  description: |
    This Policy will cause a violation if the root file system is not mounted as specified. As a security practice, the root file system should be read-only or expose risk to your nodes if compromised.

    This Policy requires containers must run with a read-only root filesystem (i.e. no writable layer).
  how_to_solve: |
    Set `readOnlyRootFilesystem` in your `securityContext` to the value specified in the Policy.
    ```
    ...
      spec:
        containers:
          - securityContext:
              readOnlyRootFilesystem: <read_only>
    ```

    https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems
  category: weave.categories.pod-security
  severity: high
  targets: {kinds: [Deployment, Job, ReplicationController, ReplicaSet, DaemonSet, StatefulSet, CronJob]}
  controls:
    - weave.controls.mitre-attack.3.2
    - weave.controls.nist-800-190.4.4.4
  tags: [mitre-attack, nist800-190]
  parameters:
    - name: read_only
      type: boolean
      required: true
      value: true
    - name: exclude_namespace
      type: array
      required: false
      value: ["kube-system", "wego-system", "flux-system"]
    - name: exclude_label_key
      type: string
      required: false
      value:
    - name: exclude_label_value
      type: string
      required: false
      value:
  code: |-
    package weave.advisor.podSecurity.enforce_ro_fs
    import future.keywords.in

    read_only = input.parameters.read_only
    excluded_namespaces := input.parameters.exclude_namespace
    exclude_label_key := input.parameters.exclude_label_key
    exclude_label_value := input.parameters.exclude_label_value

    violation[result] {
      not controller_input.metadata.namespace in excluded_namespaces
      not exclude_label_value == controller_input.metadata.labels[exclude_label_key]
      some i
      containers := controller_spec.containers[i]
      root_fs := containers.securityContext.readOnlyRootFilesystem
      not root_fs == read_only
      result = {
        "issue detected": true,
        "msg": sprintf("readOnlyRootFilesystem should equal '%v'; detected '%v'", [read_only, root_fs]),
        "recommended_value": read_only,
        "violating_key": sprintf("spec.template.spec.containers[%v].securityContext.readOnlyRootFilesystem", [i])
      }
    }

    # Controller input
    controller_input = input.review.object

    # controller_container acts as an iterator to get containers from the template
    controller_spec = controller_input.spec.template.spec {
      contains_kind(controller_input.kind, {"StatefulSet" , "DaemonSet", "Deployment", "Job"})
    } else = controller_input.spec {
      controller_input.kind == "Pod"
    } else = controller_input.spec.jobTemplate.spec.template.spec {
      controller_input.kind == "CronJob"
    }

    contains_kind(kind, kinds) {
      kinds[_] = kind
    }
---
apiVersion: pac.weave.works/v1
kind: Policy
metadata:
  name: weave.policies.missing-kubernetes-app-created-by-label
spec:
  id: weave.policies.missing-kubernetes-app-created-by-label
  name: Missing Kubernetes App Created By Label
  description: |
    Custom labels can help enforce organizational standards for each artifact deployed. This Policy ensure a custom label key is set in the entity's `metadata`. The Policy detects the presence of the following:

    ### owner
    A label key of `owner` will help identify who the owner of this entity is.

    ### app.kubernetes.io/name
    The name of the application

    ### app.kubernetes.io/instance
    A unique name identifying the instance of an application

    ### app.kubernetes.io/version
    The current version of the application (e.g., a semantic version, revision hash, etc.)

    ### app.kubernetes.io/part-of
    The name of a higher level application this one is part of

    ### app.kubernetes.io/managed-by
    The tool being used to manage the operation of an application

    ### app.kubernetes.io/created-by
    The controller/user who created this resource
  how_to_solve: |
    Add these custom labels to `metadata`.
    * owner
    * app.kubernetes.io/name
    * app.kubernetes.io/instance
    * app.kubernetes.io/version
    * app.kubernetes.io/name
    * app.kubernetes.io/part-of
    * app.kubernetes.io/managed-by
    * app.kubernetes.io/created-by

    ```
    metadata:
      labels:
        <label>: value
    ```
    For additional information, please check
    * https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels
  category: weave.categories.organizational-standards
  severity: low
  targets: {kinds: [Deployment, Job, ReplicationController, ReplicaSet, DaemonSet,
      StatefulSet, CronJob]}
  tags: []
  parameters:
  - name: exclude_namespace
    type: string
    required: false
    value:
  - name: exclude_label_key
    type: string
    required: false
    value:
  - name: exclude_label_value
    type: string
    required: false
    value:
---
apiVersion: pac.weave.works/v1
kind: Policy
metadata:
  name: weave.policies.container-image-pull-policy
spec:
  id: weave.policies.container-image-pull-policy
  name: Container Image Pull Policy
  description: |
    This Policy is to ensure you are setting a value for your `imagePullPolicy`.

    The `imagePullPolicy` and the tag of the image affect when the kubelet attempts to pull the specified image.

    `imagePullPolicy`: IfNotPresent: the image is pulled only if it is not already present locally.

    `imagePullPolicy`: Always: every time the kubelet launches a container, the kubelet queries the container image registry to resolve the name to an image digest. If the kubelet has a container image with that exact digest cached locally, the kubelet uses its cached image; otherwise, the kubelet downloads (pulls) the image with the resolved digest, and uses that image to launch the container.

    `imagePullPolicy` is omitted and either the image tag is :latest or it is omitted: `imagePullPolicy` is automatically set to Always. Note that this will not be updated to IfNotPresent if the tag changes value.

    `imagePullPolicy` is omitted and the image tag is present but not :latest: `imagePullPolicy` is automatically set to IfNotPresent. Note that this will not be updated to Always if the tag is later removed or changed to :latest.

    `imagePullPolicy`: Never: the image is assumed to exist locally. No attempt is made to pull the image.
  how_to_solve: |
    Ensure you have an imagePullPolicy set that matches your policy.
    ```
    ...
      spec:
        containers:
        - imagePullPolicy: <policy>
    ```
    https://kubernetes.io/docs/concepts/configuration/overview/#container-images
  category: weave.categories.software-supply-chain
  severity: medium
  targets: {kinds: [Deployment, Job, ReplicationController, ReplicaSet, DaemonSet,
      StatefulSet, CronJob]}
  parameters:
  - name: policy
    type: string
    required: true
    value: Always
  - name: exclude_namespace
    type: string
    required: false
    value:
  - name: exclude_label_key
    type: string
    required: false
    value:
  - name: exclude_label_value
    type: string
    required: false
    value:
